{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql.functions import length\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('coronatweets').getOrCreate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the dataset \n",
    "df=spark.read.csv('Corona_NLP_train.csv', header = True, inferSchema=True,sep= ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
      "|            UserName|          ScreenName|            Location|           Sentiment|   TweetAt|       OriginalTweet|\n",
      "+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
      "|                3799|               48751|              London|             Neutral|16-03-2020|@MeNyrbie @Phil_G...|\n",
      "|                3800|               48752|                  UK|            Positive|16-03-2020|advice Talk to yo...|\n",
      "|                3801|               48753|           Vagabonds|            Positive|16-03-2020|Coronavirus Austr...|\n",
      "|                3802|               48754|                null|            Positive|16-03-2020|My food stock is ...|\n",
      "|              PLEASE|         don't panic| THERE WILL BE EN...|                null|      null|                null|\n",
      "|           Stay calm|          stay safe.|                null|                null|      null|                null|\n",
      "|#COVID19france #C...|                null|                null|                null|      null|                null|\n",
      "|                3803|               48755|                null|  Extremely Negative|16-03-2020|Me, ready to go a...|\n",
      "|Not because I'm p...| but because my f...|          but please| don't panic. It ...|      null|                null|\n",
      "|#CoronavirusFranc...|                null|                null|                null|      null|                null|\n",
      "|                3804|               48756|ÃœT: 36.319708,-82...|            Positive|16-03-2020|As news of the re...|\n",
      "|                3805|               48757|35.926541,-78.753267|            Positive|16-03-2020|\"Cashier at groce...|\n",
      "|                3806|               48758|             Austria|             Neutral|16-03-2020|Was at the superm...|\n",
      "|#toiletpapercrisi...|                null|                null|                null|      null|                null|\n",
      "|                3807|               48759|     Atlanta, GA USA|            Positive|16-03-2020|Due to COVID-19 o...|\n",
      "|                3808|               48760|    BHAVNAGAR,GUJRAT|            Negative|16-03-2020|For corona preven...|\n",
      "|                3809|               48761|      Makati, Manila|             Neutral|16-03-2020|All month there h...|\n",
      "|                3810|               48762|Pitt Meadows, BC,...|  Extremely Positive|16-03-2020|Due to the Covid-...|\n",
      "|The wait time may...| particularly bee...|                null|                null|      null|                null|\n",
      "|We thank you for ...|                null|                null|                null|      null|                null|\n",
      "+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#viewing the dataset\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- UserName: string (nullable = true)\n",
      " |-- ScreenName: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Sentiment: string (nullable = true)\n",
      " |-- TweetAt: string (nullable = true)\n",
      " |-- OriginalTweet: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UserName', 'ScreenName', 'Location', 'Sentiment', 'TweetAt', 'OriginalTweet']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting to know the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65074\n"
     ]
    }
   ],
   "source": [
    "#dropping the duplicate values\n",
    "df = df.dropDuplicates()\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32621\n"
     ]
    }
   ],
   "source": [
    "#dropping null values\n",
    "df = df.na.drop()\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining sentiments of the dataset\n",
    "sentiments = ['Positive','Negative','Neutral','Extremely Positive','Extremely Negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering out data in the dataset\n",
    "df = df.filter(df.Sentiment.isin(sentiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting different sentiments\n",
    "df.select('Sentiment').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|         Sentiment|\n",
      "+------------------+\n",
      "|Extremely Negative|\n",
      "|           Neutral|\n",
      "|          Positive|\n",
      "|          Negative|\n",
      "|Extremely Positive|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#showing different sentiments\n",
    "df.select('Sentiment').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.withColumn('length', length(df['OriginalTweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+------------------+----------+--------------------+------+\n",
      "|UserName|ScreenName|            Location|         Sentiment|   TweetAt|       OriginalTweet|length|\n",
      "+--------+----------+--------------------+------------------+----------+--------------------+------+\n",
      "|    3926|     48878| ????? ???? ????????|          Negative|16-03-2020|#unpopularopinion...|   175|\n",
      "|    4155|     49107|      Owensboro, KY |           Neutral|16-03-2020|Just online shopp...|    80|\n",
      "|    4247|     49199|            New York|          Positive|16-03-2020|I know a lot of g...|   269|\n",
      "|    4949|     49901|         Houston, TX|          Positive|17-03-2020|Our latest issue ...|   164|\n",
      "|    5065|     50017|  Manchester, Europe|Extremely Positive|17-03-2020|If you are health...|   202|\n",
      "|    5322|     50274|      Leeds, England|          Positive|17-03-2020|#COVID2019 local ...|   191|\n",
      "|    5766|     50718|          upstate NY|          Negative|17-03-2020|Seeing those empt...|   181|\n",
      "|    6180|     51132|          Texas, USA|          Positive|17-03-2020|Governor @GregAbb...|   120|\n",
      "|    6209|     51161|          Dallas, TX|           Neutral|17-03-2020|U.S. retail sales...|   182|\n",
      "|    6270|     51222|        Georgia, USA|          Negative|17-03-2020|So no gatherings ...|   192|\n",
      "|    6290|     51242|    Williamsport, MD|          Negative|17-03-2020|This #coronavirus...|   193|\n",
      "|    6328|     51280|        The Islands |           Neutral|17-03-2020|What about all of...|   274|\n",
      "|    6333|     51285|        St.Louis, MO|Extremely Negative|17-03-2020|Next time an idio...|   160|\n",
      "|    6359|     51311|     Los Angeles, CA|          Positive|17-03-2020|An interesting lo...|    73|\n",
      "|    6735|     51687|Salt Lake City, Utah|           Neutral|18-03-2020|LISTEN: @abc4utah...|    24|\n",
      "|    6798|     51750|        New York, NY|Extremely Positive|18-03-2020|Practicing social...|   213|\n",
      "|    7246|     52198|         Philippines|           Neutral|18-03-2020|Lazada, Shopee, a...|    84|\n",
      "|    7399|     52351|    Washington, D.C.|Extremely Positive|18-03-2020|'Our absolute goa...|   131|\n",
      "|    7890|     52842|     Bakersfield, CA|           Neutral|18-03-2020|Police said they ...|   172|\n",
      "|    8349|     53301|       Working on it|           Neutral|18-03-2020|Me Vs #coronaviru...|    83|\n",
      "+--------+----------+--------------------+------------------+----------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|         Sentiment|       avg(length)|\n",
      "+------------------+------------------+\n",
      "|Extremely Negative|179.08476571697668|\n",
      "|           Neutral|134.06076810889644|\n",
      "|          Positive| 167.5731693929081|\n",
      "|          Negative|165.74478227261014|\n",
      "|Extremely Positive|183.49146433990896|\n",
      "+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculating the mean length of different sentiments\n",
    "df.groupby('Sentiment').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing tokenizer\n",
    "\n",
    "tokenizer=Tokenizer(inputCol=\"OriginalTweet\", outputCol=\"token_text\")\n",
    "stopremove=StopWordsRemover(inputCol=\"token_text\", outputCol=\"stop_tokens\")\n",
    "count_vec=CountVectorizer(inputCol=\"stop_tokens\", outputCol=\"c_vec\")\n",
    "idf=IDF(inputCol=\"c_vec\", outputCol=\"tf_idf\")\n",
    "label_to_num = StringIndexer(inputCol=\"sentiment\", outputCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = VectorAssembler(inputCols=['tf_idf','length'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the model\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "df_prep_pipeline= Pipeline(stages=[label_to_num, tokenizer, stopremove,count_vec, idf,cleaned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the model on the data\n",
    "cleaned_df= df_prep_pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming the data\n",
    "cleaned_df=cleaned_df.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+------------------+----------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|UserName|ScreenName|            Location|         sentiment|   TweetAt|       OriginalTweet|length|label|          token_text|         stop_tokens|               c_vec|              tf_idf|            features|\n",
      "+--------+----------+--------------------+------------------+----------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|    3926|     48878| ????? ???? ????????|          Negative|16-03-2020|#unpopularopinion...|   175|  1.0|[#unpopularopinio...|[#unpopularopinio...|(80619,[5,56,60,8...|(80619,[5,56,60,8...|(80620,[5,56,60,8...|\n",
      "|    4155|     49107|      Owensboro, KY |           Neutral|16-03-2020|Just online shopp...|    80|  2.0|[just, online, sh...|[online, shopping...|(80619,[6,13,14,8...|(80619,[6,13,14,8...|(80620,[6,13,14,8...|\n",
      "|    4247|     49199|            New York|          Positive|16-03-2020|I know a lot of g...|   269|  0.0|[i, know, a, lot,...|[know, lot, groce...|(80619,[0,3,7,17,...|(80619,[0,3,7,17,...|(80620,[0,3,7,17,...|\n",
      "|    4949|     49901|         Houston, TX|          Positive|17-03-2020|Our latest issue ...|   164|  0.0|[our, latest, iss...|[latest, issue, e...|(80619,[2,10,15,3...|(80619,[2,10,15,3...|(80620,[2,10,15,3...|\n",
      "|    5065|     50017|  Manchester, Europe|Extremely Positive|17-03-2020|If you are health...|   202|  3.0|[if, you, are, he...|[healthy,, risk, ...|(80619,[0,5,6,17,...|(80619,[0,5,6,17,...|(80620,[0,5,6,17,...|\n",
      "|    5322|     50274|      Leeds, England|          Positive|17-03-2020|#COVID2019 local ...|   191|  0.0|[#covid2019, loca...|[#covid2019, loca...|(80619,[5,16,19,4...|(80619,[5,16,19,4...|(80620,[5,16,19,4...|\n",
      "|    5766|     50718|          upstate NY|          Negative|17-03-2020|Seeing those empt...|   181|  1.0|[seeing, those, e...|[seeing, empty, s...|(80619,[3,7,16,56...|(80619,[3,7,16,56...|(80620,[3,7,16,56...|\n",
      "|    6180|     51132|          Texas, USA|          Positive|17-03-2020|Governor @GregAbb...|   120|  0.0|[governor, @grega...|[governor, @grega...|(80619,[38,45,116...|(80619,[38,45,116...|(80620,[38,45,116...|\n",
      "|    6209|     51161|          Dallas, TX|           Neutral|17-03-2020|U.S. retail sales...|   182|  2.0|[u.s., retail, sa...|[u.s., retail, sa...|(80619,[9,59,91,2...|(80619,[9,59,91,2...|(80620,[9,59,91,2...|\n",
      "|    6270|     51222|        Georgia, USA|          Negative|17-03-2020|So no gatherings ...|   192|  1.0|[so, no, gatherin...|[gatherings, 10, ...|(80619,[3,7,45,56...|(80619,[3,7,45,56...|(80620,[3,7,45,56...|\n",
      "|    6290|     51242|    Williamsport, MD|          Negative|17-03-2020|This #coronavirus...|   193|  1.0|[this, #coronavir...|[#coronavirus, sc...|(80619,[0,7,47,59...|(80619,[0,7,47,59...|(80620,[0,7,47,59...|\n",
      "|    6328|     51280|        The Islands |           Neutral|17-03-2020|What about all of...|   274|  2.0|[what, about, all...|[us, cash, regist...|(80619,[0,3,8,12,...|(80619,[0,3,8,12,...|(80620,[0,3,8,12,...|\n",
      "|    6333|     51285|        St.Louis, MO|Extremely Negative|17-03-2020|Next time an idio...|   160|  4.0|[next, time, an, ...|[next, time, idio...|(80619,[0,3,7,17,...|(80619,[0,3,7,17,...|(80620,[0,3,7,17,...|\n",
      "|    6359|     51311|     Los Angeles, CA|          Positive|17-03-2020|An interesting lo...|    73|  0.0|[an, interesting,...|[interesting, loo...|(80619,[0,13,14,1...|(80619,[0,13,14,1...|(80620,[0,13,14,1...|\n",
      "|    6735|     51687|Salt Lake City, Utah|           Neutral|18-03-2020|LISTEN: @abc4utah...|    24|  2.0|[listen:, @abc4ut...|[listen:, @abc4ut...|(80619,[27806,506...|(80619,[27806,506...|(80620,[27806,506...|\n",
      "|    6798|     51750|        New York, NY|Extremely Positive|18-03-2020|Practicing social...|   213|  3.0|[practicing, soci...|[practicing, soci...|(80619,[1,6,11,36...|(80619,[1,6,11,36...|(80620,[1,6,11,36...|\n",
      "|    7246|     52198|         Philippines|           Neutral|18-03-2020|Lazada, Shopee, a...|    84|  2.0|[lazada,, shopee,...|[lazada,, shopee,...|(80619,[6,665,118...|(80619,[6,665,118...|(80620,[6,665,118...|\n",
      "|    7399|     52351|    Washington, D.C.|Extremely Positive|18-03-2020|'Our absolute goa...|   131|  3.0|['our, absolute, ...|['our, absolute, ...|(80619,[4,6,51,54...|(80619,[4,6,51,54...|(80620,[4,6,51,54...|\n",
      "|    7890|     52842|     Bakersfield, CA|           Neutral|18-03-2020|Police said they ...|   172|  2.0|[police, said, th...|[police, said, re...|(80619,[3,7,8,31,...|(80619,[3,7,8,31,...|(80620,[3,7,8,31,...|\n",
      "|    8349|     53301|       Working on it|           Neutral|18-03-2020|Me Vs #coronaviru...|    83|  2.0|[me, vs, #coronav...|[vs, #coronavirus...|(80619,[0,4,21,36...|(80619,[0,4,21,36...|(80620,[0,4,21,36...|\n",
      "+--------+----------+--------------------+------------------+----------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#viewing the cleaned data \n",
    "cleaned_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df=cleaned_df.select(['label', 'features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  1.0|(80620,[5,56,60,8...|\n",
      "|  2.0|(80620,[6,13,14,8...|\n",
      "|  0.0|(80620,[0,3,7,17,...|\n",
      "|  0.0|(80620,[2,10,15,3...|\n",
      "|  3.0|(80620,[0,5,6,17,...|\n",
      "|  0.0|(80620,[5,16,19,4...|\n",
      "|  1.0|(80620,[3,7,16,56...|\n",
      "|  0.0|(80620,[38,45,116...|\n",
      "|  2.0|(80620,[9,59,91,2...|\n",
      "|  1.0|(80620,[3,7,45,56...|\n",
      "|  1.0|(80620,[0,7,47,59...|\n",
      "|  2.0|(80620,[0,3,8,12,...|\n",
      "|  4.0|(80620,[0,3,7,17,...|\n",
      "|  0.0|(80620,[0,13,14,1...|\n",
      "|  2.0|(80620,[27806,506...|\n",
      "|  3.0|(80620,[1,6,11,36...|\n",
      "|  2.0|(80620,[6,665,118...|\n",
      "|  3.0|(80620,[4,6,51,54...|\n",
      "|  2.0|(80620,[3,7,8,31,...|\n",
      "|  2.0|(80620,[0,4,21,36...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#viewing columns\n",
    "cleaned_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the dataset\n",
    "#Spilting the data into train and test\n",
    "(training, testing)=cleaned_df.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Random Forest\n",
    "#fitting the model on the dataset\n",
    "spam_predictor_rf=rf.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming the model\n",
    "test_results_rf=spam_predictor_rf.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(80620,[0,1,3,7,6...|[5.60104606499630...|[0.28005230324981...|       0.0|\n",
      "|  0.0|(80620,[0,2,12,70...|[5.53855401644105...|[0.27692770082205...|       0.0|\n",
      "|  0.0|(80620,[0,3,12,21...|[5.69880669421629...|[0.28494033471081...|       0.0|\n",
      "|  0.0|(80620,[0,5,8,23,...|[5.56385121263016...|[0.27819256063150...|       0.0|\n",
      "|  0.0|(80620,[0,9,12,10...|[5.36301256333227...|[0.26815062816661...|       0.0|\n",
      "|  0.0|(80620,[0,9,12,12...|[5.55481383646610...|[0.27774069182330...|       0.0|\n",
      "|  0.0|(80620,[0,12,24,3...|[5.6518393691567,...|[0.28259196845783...|       0.0|\n",
      "|  0.0|(80620,[0,13,14,1...|[5.55481383646610...|[0.27774069182330...|       0.0|\n",
      "|  0.0|(80620,[0,13,46,8...|[5.46099572704180...|[0.27304978635209...|       0.0|\n",
      "|  0.0|(80620,[0,22,26,3...|[5.55481383646610...|[0.27774069182330...|       0.0|\n",
      "|  0.0|(80620,[1,10,15,5...|[5.55481383646610...|[0.27774069182330...|       0.0|\n",
      "|  0.0|(80620,[2,10,15,3...|[5.48488913272779...|[0.27424445663638...|       0.0|\n",
      "|  0.0|(80620,[2,71,131,...|[5.53855401644105...|[0.27692770082205...|       0.0|\n",
      "|  0.0|(80620,[3,7,10,34...|[5.59200868883225...|[0.27960043444161...|       0.0|\n",
      "|  0.0|(80620,[5,6,16,31...|[5.55481383646610...|[0.27774069182330...|       0.0|\n",
      "|  0.0|(80620,[5,16,19,4...|[5.55587609102092...|[0.27779380455104...|       0.0|\n",
      "|  0.0|(80620,[6,7,48,92...|[5.59200868883225...|[0.27960043444161...|       0.0|\n",
      "|  0.0|(80620,[6,11,13,1...|[5.55481383646610...|[0.27774069182330...|       0.0|\n",
      "|  0.0|(80620,[6,28,33,2...|[5.55481383646610...|[0.27774069182330...|       0.0|\n",
      "|  0.0|(80620,[38,45,116...|[5.55481383646610...|[0.27774069182330...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#viewing the results of the test data\n",
    "test_results_rf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.28523215381468603\n"
     ]
    }
   ],
   "source": [
    "#evaluating the accuracy of the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    " metricName=\"accuracy\")\n",
    "accuracy_rf = evaluator.evaluate(test_results_rf)\n",
    "print(\"Test set accuracy = \" + str(accuracy_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
